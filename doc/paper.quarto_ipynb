{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: |\n",
        "  | Earnings Management and Investor Protection:\n",
        "  | Accounting Reading Group - Assignment III\\vspace{1cm}\n",
        "author:\n",
        "  - name: Melisa Mazaeva\n",
        "    email: melisa.mazaeva@student.hu-berlin.de\n",
        "    affiliations:\n",
        "      - Humboldt-Universität zu Berlin  \n",
        "date: today\n",
        "date-format: MMM D, YYYY [\\vspace{1cm}]\n",
        "abstract: |\n",
        "  | This project uses the TRR 266 Template for Reproducible Empirical Accounting Research (TREAT) to provide an infrastructure for open science-oriented empirical projects. Leveraging external Worldscope data sets on financial data, the repository showcases a reproducible workflow that integrates Python scripts for data analysis. The project’s output demonstrates a comprehensive application of skills to replicate and extend the findings from the seminal paper by Leuz, Nanda, and Wysocki (2003), particularly in providing descriptive statistics for the four individual earnings management measures as well as the aggregate earnings management score across various countries. In doing so, it documents and discusses the research design choices made and the variations between the original and reproduced results. This code base, adapted from TREAT, should give you an overview on how the template is supposed to be used for my specific project and how to structure a reproducible empirical project.\n",
        "  | \\vspace{6cm}\n",
        "bibliography: references.bib\n",
        "biblio-style: apsr\n",
        "format:\n",
        "  pdf:\n",
        "    documentclass: article\n",
        "    number-sections: true\n",
        "    toc: false\n",
        "fig_caption: yes\n",
        "fontsize: 11pt\n",
        "ident: yes\n",
        "always_allow_html: yes\n",
        "header-includes:\n",
        "  - \\usepackage[nolists]{endfloat}    \n",
        "  - \\usepackage{setspace}\\doublespacing\n",
        "  - \\setlength{\\parindent}{4em}\n",
        "  - \\setlength{\\parskip}{0em}\n",
        "  - \\usepackage[hang,flushmargin]{footmisc}\n",
        "  - \\usepackage{caption} \n",
        "  - \\captionsetup[table]{skip=24pt,font=bf}\n",
        "  - \\usepackage{array}\n",
        "  - \\usepackage{threeparttable}\n",
        "  - \\usepackage{adjustbox}\n",
        "  - \\usepackage{graphicx}\n",
        "  - \\usepackage{csquotes}\n",
        "  - \\usepackage{indentfirst}  # Added this line to ensure the first paragraph is indented for better readability\n",
        "  - \\usepackage[margin=1in]{geometry}\n",
        "---\n",
        "\n",
        "\n",
        "\\pagebreak\n",
        "\n",
        "## delete or take fikirs below"
      ],
      "id": "4dd4ec72"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| output: false\n",
        "\n",
        "import pickle\n",
        "\n",
        "with open('../output/results.pickle', 'rb') as f:\n",
        "        results = pickle.load(f)\n",
        "\n",
        "min_fyear, max_fyear, no_unique_firms = results['Desc information'].values()\n",
        "\n",
        "\n",
        "def rename_var_to_label(table, italic=True):\n",
        "    for var_name, var_label in results['Variable Names'].items():\n",
        "        var_label = f'\\\\textit{{{var_label}}}' if italic else var_label\n",
        "        table = table.replace(var_name, var_label)\n",
        "    return table"
      ],
      "id": "58ccdd1d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## from fikir"
      ],
      "id": "65aec778"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| output: false\n",
        "\n",
        "import pickle\n",
        "import pandas as pd\n",
        "\n",
        "with open('../output/results.pickle', 'rb') as f:\n",
        "        results = pickle.load(f)\n",
        "\n",
        "def escape_underscores(df):\n",
        "    df.columns = [col.replace('_', '\\_') for col in df.columns]\n",
        "    return df\n",
        "\n",
        "# Custom formatter function\n",
        "def custom_float_format(x):\n",
        "    return f\"{x:.3f}\".lstrip('0') if pd.notnull(x) else \"\"\n",
        "\n",
        "\n",
        "def prep_latex_table(df, caption=None, label=None):\n",
        "    df = escape_underscores(df.reset_index())\n",
        "    num_columns = len(df.columns)\n",
        "    column_format = 'l' + 'r' * (num_columns - 1)\n",
        "    latex_table = df.to_latex(\n",
        "        column_format=column_format,\n",
        "        index=False,\n",
        "        float_format=custom_float_format,\n",
        "    )\n",
        "    latex_table_lines = [\n",
        "        \"\\\\begin{table}[htbp]\",\n",
        "        \"\\\\centering\",\n",
        "        \"\\\\resizebox{\\\\textwidth}{!}{%\",\n",
        "        latex_table,\n",
        "        \"}\",\n",
        "        f\"\\\\caption{{{caption}}}\" if caption else \"\",\n",
        "        f\"\\\\label{{{label}}}\" if label else \"\",\n",
        "        \"\\\\end{table}\"\n",
        "    ]\n",
        "    return \"\\n\".join(line for line in latex_table_lines if line)"
      ],
      "id": "ab0de54d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\\pagebreak\n",
        "\n",
        "\n",
        "# Research Design Choices and Assumptions\n",
        "\n",
        "The aim of Assignment III is to replicate a specific empirical table (Table 2 Panel A) from the seminal paper by @Leuz_2003. This table involves calculating the EM measures for firms across various countries over a defined period and examining the relationship between these measures and investor protection. The replication process includes data loading, preparation, cleaning, and normalization, followed by the application of statistical methods to compute and interpret financial metrics. For Assignment III, I pulled data from the Worldscope database through WRDS and used the Python programming language to carry out the empirical analysis. Visual Studio Code was used as the Integrated Development Environment (IDE) for writing, debugging, and optimizing the Python code.\n",
        "\n",
        "The replication is based on data pulled from the Worldscope database, specifically from the `wrds_ws_company` and `wrds_ws_funda` tables, which were merged for the analysis. The first table provides company profile information, including items such as ISIN, Worldscope Identifiers, company name, and the country where the company is domiciled. The latter table contains Fundamentals Annual data at the company-year level, including items such total assets, net income, and other relevant financial variables.\n",
        "\n",
        "Following @Leuz_2003, I focus the analysis on companies across various countries, ensuring that the data accurately reflects the fiscal years 1990 to 1999 as specified in the original study. The replication aims to mirror the research design as closely as possible with the available data.\n",
        "\n",
        "In addition, I impose the following assumptions to ensure clarity and consistency where the paper does not provide explicit guidance:\n",
        "\n",
        "## check assumptions in Fikir and mine\n",
        "1. The original paper references the November 2000 version of the Worldscope Database. However, the data used for this analysis represents the latest available version, updated in July 2024, with quarterly frequency updates [@WRDS_2024]. Due to potential adjustments and updates made to the database since November 2000, there may be differences between the databases that could affect the results. For example, companies may restate financials after the original reporting period, so that these restatements are reflected in the later database version rather than the historical one. Moreover, the data vendor Refinitiv regularly updates its databases to correct errors and add new information, which may be included in the later data but not in the November 2000 snapshot.\n",
        "2. While pulling the data for analysis, I encountered negative values for some key financial metrics such as operating income (`item1250`), net income before extraordinary items/preferred dividends (`item1551`), and net income before preferred dividends (`item1651`). The paper by @Leuz_2003 does not explicitly specify how to handle negative values in key financial metrics. For the purpose of this replication study, I will include negative values in the analysis. Including these values ensures that the analysis captures the full spectrum of earnings management activities across different countries.\n",
        "3. The EM measures are based on scaled variables (e.g., operating cash flow scaled by lagged total assets). As such, the currency of the relevant data items should not affect the results as long as the same currency is used consistently for both the numerator and the denominator. This approach ensures comparability across different countries, regardless of their local currencies. Additionally, according to a document by [@Thomson_Financial_2007, p.20], all Worldscope data is consistently reported in the local currency of each firm’s country of domicile, eliminating the need for currency conversions in this project.\n",
        "333. ## delete. mine \n",
        "333. It is assumed that Penman (2013) restricted the possible P/B values to a range of 0 to 7 to exclude outliers. Hence, extreme P/B values that are negative and very high (greater than 7) are excluded to focus the analysis on firms with more stable and reasonable valuations, reducing the impact of outliers.\n",
        "\n",
        "By following the steps provided in Section 4 and adhering to the assumptions made, I successfully replicated the analysis and produced the required table. A thorough step-by-step approach, with each step clearly documented,  helped to understand and verify the outputs.\n",
        "\n",
        "\n",
        "# Replication Steps\n",
        "## Step 1: Pulling the Data and Managing the Databases\n",
        "In contrast to Assignment I, where the data was provided externally, Assignment III involves additionally pulling data directly from the Worldscope database, merging relevant tables, and preparing the data for further analysis from raw data to final output.\n",
        "\n",
        "To compile the dataset, the dynamic and static datasets were merged on the `item6105`  identifier, representing the unique Worldscope Permanent ID. WRDS advises using this identifier consistently within Worldscope data since it remains stable over time [@WRDS_Overview_2024].\n",
        "\n",
        "\\pagebreak\n",
        "\n",
        "\\setcounter{table}{0}\n",
        "\\renewcommand{\\thetable}{\\arabic{table}}\n",
        "\n",
        "# References {-}\n",
        "\\setlength{\\parindent}{-0.2in}\n",
        "\\setlength{\\leftskip}{0.2in}\n",
        "\\setlength{\\parskip}{8pt}\n",
        "\\noindent"
      ],
      "id": "c024caad"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Users/melissam/Library/Python/3.12/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}